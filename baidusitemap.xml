<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">


    
  <url>
    <loc>txshi-mt.com/2018/02/04/CS20-6-Introduction-to-CNN/</loc>
    <lastmod>2018-02-07T05:05:27.977Z</lastmod>
    <data>
        <display>
        <title>CS20 06. 卷积神经网络简介</title>
        <pubTime>2018-02-04T13:41:41.000Z</pubTime>
        
        <tag>CS20</tag>
         
        <tag>CNN</tag>
         
         
           
             
              <breadCrumb title="深度学习" url="txshi-mt.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2018/02/04/UTNN-11-Hopfield-Nets-and-Boltzmann-Machines/</loc>
    <lastmod>2018-02-07T01:24:36.055Z</lastmod>
    <data>
        <display>
        <title>Hinton神经网络与机器学习 11. Hopfield网和玻尔兹曼机</title>
        <pubTime>2018-02-04T10:25:31.000Z</pubTime>
        
        <tag>UTNN</tag>
         
        <tag>Hopfield网</tag>
         
        <tag>玻尔兹曼机</tag>
         
        <tag>模拟退火</tag>
         
         
           
             
              <breadCrumb title="深度学习" url="txshi-mt.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2018/01/31/UTNN-10-Combining-Multiple-Neural-Networks-to-Improve-Generalization/</loc>
    <lastmod>2018-02-04T10:06:57.909Z</lastmod>
    <data>
        <display>
        <title>Hinton神经网络与机器学习 10. 组合多个神经网络以提高泛化能力</title>
        <pubTime>2018-01-31T11:53:01.000Z</pubTime>
        
        <tag>UTNN</tag>
         
        <tag>dropout</tag>
         
        <tag>模型组合</tag>
         
         
           
             
              <breadCrumb title="深度学习" url="txshi-mt.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2018/01/29/CS20-5-Variable-Sharing-and-Experiments-Management/</loc>
    <lastmod>2018-01-29T15:08:55.622Z</lastmod>
    <data>
        <display>
        <title>CS20 05. 变量共享与实验管理</title>
        <pubTime>2018-01-29T12:24:36.000Z</pubTime>
        
        <tag>TensorFlow</tag>
         
        <tag>CS20</tag>
         
        <tag>变量共享</tag>
         
         
           
             
              <breadCrumb title="深度学习实践" url="txshi-mt.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2018/01/24/CS20-4-Eager-Execution-and-Word2vec/</loc>
    <lastmod>2018-01-29T15:08:32.866Z</lastmod>
    <data>
        <display>
        <title>CS20 04. Eager Execution与word2vec</title>
        <pubTime>2018-01-24T07:30:18.000Z</pubTime>
        
        <tag>TensorFlow</tag>
         
        <tag>CS20SI</tag>
         
        <tag>词向量</tag>
         
         
           
             
              <breadCrumb title="深度学习实践" url="txshi-mt.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/"/>
          
             
              <breadCrumb title="NLP" url="txshi-mt.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/NLP/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/11/29/CS20-3-Linear-and-Logistic-Regression/</loc>
    <lastmod>2018-01-24T07:15:15.000Z</lastmod>
    <data>
        <display>
        <title>CS20SI 03. 线性与Logistic回归</title>
        <pubTime>2017-11-29T15:58:33.000Z</pubTime>
        
        <tag>TensorFlow</tag>
         
        <tag>CS20SI</tag>
         
         
           
             
              <breadCrumb title="深度学习实践" url="txshi-mt.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2018/01/20/UTNN-9-Ways-to-Make-Neural-Networks-Generalize-Better/</loc>
    <lastmod>2018-01-22T10:51:55.000Z</lastmod>
    <data>
        <display>
        <title>Hinton神经网络与机器学习 9. 提高神经网络的泛化能力</title>
        <pubTime>2018-01-20T14:05:05.000Z</pubTime>
        
        <tag>正则化</tag>
         
        <tag>UTNN</tag>
         
         
           
             
              <breadCrumb title="深度学习" url="txshi-mt.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/11/26/CS20-2-Operations/</loc>
    <lastmod>2018-01-19T04:34:05.000Z</lastmod>
    <data>
        <display>
        <title>CS20SI 02. 操作</title>
        <pubTime>2017-11-26T07:29:39.000Z</pubTime>
        
        <tag>TensorFlow</tag>
         
        <tag>CS20SI</tag>
         
         
           
             
              <breadCrumb title="深度学习实践" url="txshi-mt.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2018/01/16/UTNN-8-Recurrent-Neural-Networks-2/</loc>
    <lastmod>2018-01-17T14:54:03.000Z</lastmod>
    <data>
        <display>
        <title>Hinton神经网络与机器学习 8. 循环神经网络 II</title>
        <pubTime>2018-01-16T14:05:53.000Z</pubTime>
        
        <tag>UTNN</tag>
         
        <tag>RNN</tag>
         
        <tag>ESN</tag>
         
        <tag>HF优化</tag>
         
         
           
             
              <breadCrumb title="深度学习" url="txshi-mt.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2018/01/07/UTNN-7-Recurrent-Neural-Networks/</loc>
    <lastmod>2018-01-16T14:12:43.000Z</lastmod>
    <data>
        <display>
        <title>Hinton神经网络与机器学习 7. 循环神经网络 I</title>
        <pubTime>2018-01-07T09:03:08.000Z</pubTime>
        
        <tag>UTNN</tag>
         
        <tag>RNN</tag>
         
         
           
             
              <breadCrumb title="深度学习" url="txshi-mt.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/12/27/UTNN-6-Optimization-How-to-Make-the-Learning-Go-Faster/</loc>
    <lastmod>2018-01-07T09:09:22.000Z</lastmod>
    <data>
        <display>
        <title>Hinton神经网络与机器学习 6. 神经网络的优化</title>
        <pubTime>2017-12-27T15:51:28.000Z</pubTime>
        
        <tag>UTNN</tag>
         
        <tag>优化</tag>
         
        <tag>梯度下降</tag>
         
        <tag>动量法</tag>
         
         
           
             
              <breadCrumb title="深度学习" url="txshi-mt.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/12/23/UTNN-5-Object-Recognition-with-Neural-Nets/</loc>
    <lastmod>2018-01-07T09:09:09.000Z</lastmod>
    <data>
        <display>
        <title>Hinton神经网络与机器学习 5. 卷积神经网络</title>
        <pubTime>2017-12-23T09:52:37.000Z</pubTime>
        
        <tag>CNN</tag>
         
        <tag>UTNN</tag>
         
         
           
             
              <breadCrumb title="深度学习" url="txshi-mt.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/12/22/UTNN-4-Learning-Feature-Vectors-for-Words/</loc>
    <lastmod>2018-01-07T09:08:58.000Z</lastmod>
    <data>
        <display>
        <title>Hinton神经网络与机器学习 4. 神经语言模型与词向量</title>
        <pubTime>2017-12-22T12:44:06.000Z</pubTime>
        
        <tag>词向量</tag>
         
        <tag>UTNN</tag>
         
        <tag>语言模型</tag>
         
         
           
             
              <breadCrumb title="NLP" url="txshi-mt.com/categories/NLP/"/>
          
             
              <breadCrumb title="深度学习" url="txshi-mt.com/categories/NLP/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/11/12/UTNN-1-Introduction/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>Hinton神经网络与机器学习 1. 绪论</title>
        <pubTime>2017-11-12T02:28:56.000Z</pubTime>
        
        <tag>UTNN</tag>
         
         
           
             
              <breadCrumb title="深度学习" url="txshi-mt.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/09/10/NTUML-14-Regularization/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 14. 正则化</title>
        <pubTime>2017-09-10T11:01:29.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>正则化</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/09/14/NTUML-16-Three-Learning-Principles/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 16. 三条锦囊妙计</title>
        <pubTime>2017-09-14T13:55:21.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>机器学习实践经验</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/09/18/NTUML-18-Dual-SVM/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 18. 对偶支持向量机</title>
        <pubTime>2017-09-18T15:47:13.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>SVM</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/08/03/NTUML-2-Learning-to-Answer-Yes-No/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 2. 学习判断是与非</title>
        <pubTime>2017-08-03T10:24:15.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>感知机</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/09/18/NTUML-17-Linear-SVM/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 17. 线性支持向量机</title>
        <pubTime>2017-09-18T15:44:08.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>SVM</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/09/23/NTUML-19-Kernel-SVM/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 19. 核支持向量机</title>
        <pubTime>2017-09-23T02:28:59.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>SVM</tag>
         
        <tag>核方法</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/10/02/NTUML-21-Kernel-Logistic-Regression/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 21. 核Logistic回归</title>
        <pubTime>2017-10-02T02:19:24.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>Logistic回归</tag>
         
        <tag>SVM</tag>
         
        <tag>核方法</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/10/03/NTUML-22-SVR/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 22. 支持向量回归（SVR）</title>
        <pubTime>2017-10-03T02:09:48.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>SVM</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/09/23/NTUML-20-Soft-Margin-SVM/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 20. 软间隔支持向量机</title>
        <pubTime>2017-09-23T02:29:11.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>SVM</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/10/07/NTUML-25-Decision-Tree/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 25. 决策树</title>
        <pubTime>2017-10-07T02:02:21.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>决策树</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/10/05/NTUML-24-Adaptive-Boosting/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 24. 自适应提升算法（Adaptive Boosting）</title>
        <pubTime>2017-10-05T07:58:11.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>Boosting</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/10/05/NTUML-23-Blending-Bagging/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 23. 模型混合与装袋（bagging）</title>
        <pubTime>2017-10-05T00:52:59.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>bagging</tag>
         
        <tag>stacking</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/10/07/NTUML-26-Random-Forest/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 26. 随机森林</title>
        <pubTime>2017-10-07T15:44:51.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>随机森林</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/10/14/NTUML-27-GBDT/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 27. 梯度提升决策树（GBDT）</title>
        <pubTime>2017-10-14T09:34:05.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>gbdt</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/10/21/NTUML-29-Deep-Learning/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 29. 深度学习</title>
        <pubTime>2017-10-21T09:43:37.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>自动编码器</tag>
         
        <tag>PCA</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
             
              <breadCrumb title="深度学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/10/22/NTUML-30-RBF-Network/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 30. 径向基函数网络</title>
        <pubTime>2017-10-22T10:02:28.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>kNN</tag>
         
        <tag>k均值聚类</tag>
         
        <tag>RBF</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/10/25/NTUML-31-Matrix-Factorization/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 31. 矩阵分解</title>
        <pubTime>2017-10-25T13:46:25.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>矩阵分解</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/10/19/NTUML-28-Neural-Network/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 28. 神经网络</title>
        <pubTime>2017-10-19T13:20:06.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>神经网络入门</tag>
         
         
           
             
              <breadCrumb title="深度学习" url="txshi-mt.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/08/06/NTUML-4-Feasibility-of-Learning/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 4. 机器学习的可行性</title>
        <pubTime>2017-08-06T03:29:30.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>统计学习理论</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/08/05/NTUML-3-Types-of-Learning/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 3. 机器学习的类型</title>
        <pubTime>2017-08-05T11:30:08.000Z</pubTime>
        
        <tag>NTUML</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/10/28/NTUML-32-Finale/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 32. 结束曲</title>
        <pubTime>2017-10-28T09:28:59.000Z</pubTime>
        
        <tag>NTUML</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/08/20/NTUML-7-the-VC-Dimension/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 7. VC维</title>
        <pubTime>2017-08-20T12:18:07.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>统计学习理论</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/08/21/NTUML-8-Noise-and-Error/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 8. 噪声和错误</title>
        <pubTime>2017-08-21T12:54:37.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>统计学习理论</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/08/28/NTUML-9-Linear-Regression/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 9. 线性回归</title>
        <pubTime>2017-08-28T11:58:08.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>线性回归</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/08/14/NTUML-5-Training-versus-Testing/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 5. 训练 vs. 测试</title>
        <pubTime>2017-08-14T10:15:03.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>统计学习理论</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/12/05/DLBook-6a-Deep-Feedforward-Networks-summary/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>《深度学习》ch6. 深度前馈网络 记（上）</title>
        <pubTime>2017-12-05T15:01:20.000Z</pubTime>
        
        <tag>神经网络</tag>
         
        <tag>DLBook</tag>
         
        <tag>激活函数</tag>
         
         
           
             
              <breadCrumb title="深度学习" url="txshi-mt.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/08/16/NTUML-6-Theory-of-Generalization/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 6. 一般化理论</title>
        <pubTime>2017-08-16T06:28:47.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>统计学习理论</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/11/18/UTNN-2-the-Perceptron-Learning-Procedure/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>Hinton神经网络与机器学习 2. 感知机</title>
        <pubTime>2017-11-18T09:40:03.000Z</pubTime>
        
        <tag>感知机</tag>
         
        <tag>UTNN</tag>
         
         
           
             
              <breadCrumb title="深度学习" url="txshi-mt.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/11/21/UTNN-3-the-Backpropagation-Learning-Procedure/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>Hinton神经网络与机器学习 3. 反向传播</title>
        <pubTime>2017-11-21T14:30:52.000Z</pubTime>
        
        <tag>神经网络</tag>
         
        <tag>UTNN</tag>
         
        <tag>反向传播</tag>
         
         
           
             
              <breadCrumb title="深度学习" url="txshi-mt.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/11/25/CS20-1-Introduction/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>CS20SI 01. TensorFlow基本概念：张量、图和会话</title>
        <pubTime>2017-11-25T14:27:07.000Z</pubTime>
        
        <tag>TensorFlow</tag>
         
        <tag>CS20SI</tag>
         
         
           
             
              <breadCrumb title="深度学习实践" url="txshi-mt.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/12/09/DLBook-6a-Deep-Feedforward-Networks-notes/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>《深度学习》ch6. 深度前馈网络 注（上）</title>
        <pubTime>2017-12-09T14:40:42.000Z</pubTime>
        
        <tag>神经网络</tag>
         
        <tag>DLBook</tag>
         
        <tag>交叉熵</tag>
         
        <tag>softmax</tag>
         
         
           
             
              <breadCrumb title="深度学习" url="txshi-mt.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/08/01/NTUML-1-the-Learning-Problem/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 1. 学习问题</title>
        <pubTime>2017-08-01T12:57:28.000Z</pubTime>
        
        <tag>NTUML</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/08/30/NTUML-10-Logistic-Regression/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 10. Logistic回归</title>
        <pubTime>2017-08-30T02:51:06.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>Logistic回归</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/09/01/NTUML-11-Linear-Models-for-Classification/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 11. 用于分类问题的线性模型</title>
        <pubTime>2017-09-01T06:39:18.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>Logistic回归</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/06/24/edx-columbia-1-Intro-MLE/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>EdX Columbia ML 1. 概论与最大似然</title>
        <pubTime>2017-06-24T10:02:00.000Z</pubTime>
        
        <tag>EdX-Columbia</tag>
         
        <tag>最大似然</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/06/28/edx-columbia-10-kernel-methods-gaussian-process/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>EdX Columbia ML 10. 核方法与高斯过程</title>
        <pubTime>2017-06-28T07:53:18.000Z</pubTime>
        
        <tag>核方法</tag>
         
        <tag>EdX-Columbia</tag>
         
        <tag>高斯过程</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/09/04/NTUML-12-Nonlinear-Transformation/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 12. 非线性变换</title>
        <pubTime>2017-09-04T02:52:44.000Z</pubTime>
        
        <tag>NTUML</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/09/09/NTUML-13-Hazard-of-Overfitting/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 13. 过拟合的危害</title>
        <pubTime>2017-09-09T14:47:55.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>正则化</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/06/29/edx-columbia-11-Maximum-Margin-Classifier-SVM/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>EdX Columbia ML 11. 最大间隔分类器和支持向量机 (SVM)</title>
        <pubTime>2017-06-29T08:48:07.000Z</pubTime>
        
        <tag>SVM</tag>
         
        <tag>EdX-Columbia</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/06/29/edx-columbia-12-Decision-Tree-Random-Forest/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>EdX Columbia ML 12. 决策树与随机森林</title>
        <pubTime>2017-06-29T08:55:54.000Z</pubTime>
        
        <tag>决策树</tag>
         
        <tag>随机森林</tag>
         
        <tag>EdX-Columbia</tag>
         
        <tag>集成方法</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/06/29/edx-columbia-13-Boosting/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>EdX Columbia ML 13. Boosting</title>
        <pubTime>2017-06-29T09:02:47.000Z</pubTime>
        
        <tag>Boosting</tag>
         
        <tag>EdX-Columbia</tag>
         
        <tag>集成方法</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/07/03/edx-columbia-16-Gaussian-Mixture-Model/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>EdX Columbia ML 16. 高斯混合模型</title>
        <pubTime>2017-07-03T02:13:56.000Z</pubTime>
        
        <tag>EdX-Columbia</tag>
         
        <tag>GMM</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/07/03/edx-columbia-14-Clustering-K-Means/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>EdX Columbia ML 14. 聚类与K-均值算法</title>
        <pubTime>2017-07-03T01:52:38.000Z</pubTime>
        
        <tag>EdX-Columbia</tag>
         
        <tag>聚类</tag>
         
        <tag>kmeans</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/09/12/NTUML-15-Validation/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>NTUML 15. 验证</title>
        <pubTime>2017-09-12T12:26:32.000Z</pubTime>
        
        <tag>NTUML</tag>
         
        <tag>验证</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/07/05/edx-columbia-18-Topic-Modeling-Non-negative-Matrix-Factorization/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>EdX Columbia ML 18. 主题建模与非负矩阵分解</title>
        <pubTime>2017-07-05T09:25:26.000Z</pubTime>
        
        <tag>矩阵分解</tag>
         
        <tag>EdX-Columbia</tag>
         
        <tag>主题建模</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/07/05/edx-columbia-17-Matrix-Factorization-Collaborative-Filtering/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>Edx Columbia ML 17. 矩阵分解与协同过滤</title>
        <pubTime>2017-07-05T09:20:53.000Z</pubTime>
        
        <tag>矩阵分解</tag>
         
        <tag>EdX-Columbia</tag>
         
        <tag>协同过滤</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/07/03/edx-columbia-15-Maximum-Likelihood-EM-Algorithm/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>EdX Columbia ML 15. 最大似然的EM算法</title>
        <pubTime>2017-07-03T01:58:12.000Z</pubTime>
        
        <tag>EdX-Columbia</tag>
         
        <tag>EM算法</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/06/24/edx-columbia-2-Linear-Regression-Least-Squares/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>EdX Columbia ML 2. 线性回归与最小二乘</title>
        <pubTime>2017-06-24T12:52:00.000Z</pubTime>
        
        <tag>线性回归</tag>
         
        <tag>EdX-Columbia</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/07/05/edx-columbia-19-PCA/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>Edx Columbia ML 19. 主成分分析 (PCA)</title>
        <pubTime>2017-07-05T09:32:27.000Z</pubTime>
        
        <tag>PCA</tag>
         
        <tag>EdX-Columbia</tag>
         
        <tag>SVD</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/07/09/edx-columbia-20-Markov-Model-Semi-Supervised-Learning/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>EdX Columbia ML 20. 马尔科夫模型和半监督学习</title>
        <pubTime>2017-07-09T01:56:45.000Z</pubTime>
        
        <tag>EdX-Columbia</tag>
         
        <tag>马尔科夫模型</tag>
         
        <tag>半监督学习</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/07/09/edx-columbia-23-Association-Analysis/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>EdX Columbia ML 23. 关联分析</title>
        <pubTime>2017-07-09T10:09:54.000Z</pubTime>
        
        <tag>EdX-Columbia</tag>
         
        <tag>关联分析</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/07/09/edx-columbia-21-Hidden-Markov-Model/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>EdX Columbia ML 21. 隐马尔科夫模型 (HMM)</title>
        <pubTime>2017-07-09T02:05:47.000Z</pubTime>
        
        <tag>EdX-Columbia</tag>
         
        <tag>HMM</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/07/09/edx-columbia-22-Continuous-Status-Space-Model/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>EdX Columbia ML 22. 连续状态空间模型</title>
        <pubTime>2017-07-09T02:08:27.000Z</pubTime>
        
        <tag>EdX-Columbia</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/06/24/edx-columbia-4-Biases-Variances-Bayes-Rule-MAP-Inference/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>EdX Columbia ML 4. 偏差方差、贝叶斯定律与MAP推断</title>
        <pubTime>2017-06-24T15:08:52.000Z</pubTime>
        
        <tag>EdX-Columbia</tag>
         
        <tag>MAP</tag>
         
        <tag>贝叶斯定律</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/07/24/edx-columbia-24-Model-Selection/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>EdX Columbia ML 24. 模型选择</title>
        <pubTime>2017-07-24T12:34:22.000Z</pubTime>
        
        <tag>EdX-Columbia</tag>
         
        <tag>模型选择</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/06/26/edx-columbia-6-Spartial-Linear-Regression/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>EdX Columbia ML 6. 稀疏线性回归</title>
        <pubTime>2017-06-26T09:00:59.000Z</pubTime>
        
        <tag>线性回归</tag>
         
        <tag>EdX-Columbia</tag>
         
        <tag>LASSO</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/06/24/edx-columbia-3-Least-Squares-II-Ridge-Regression/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>EdX Columbia ML 3. 最小二乘II & 岭回归</title>
        <pubTime>2017-06-24T13:07:58.000Z</pubTime>
        
        <tag>线性回归</tag>
         
        <tag>EdX-Columbia</tag>
         
        <tag>岭回归</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/06/27/edx-columbia-8-Linear-Classifier-Perceptron/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>EdX Columbia ML 8. 线性分类器与感知机</title>
        <pubTime>2017-06-27T09:53:45.000Z</pubTime>
        
        <tag>感知机</tag>
         
        <tag>EdX-Columbia</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/06/27/edx-columbia-7-KNN-Bayes-Classifier/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>EdX Columbia ML 7. K-最近邻分类与贝叶斯分类器</title>
        <pubTime>2017-06-27T02:51:28.000Z</pubTime>
        
        <tag>EdX-Columbia</tag>
         
        <tag>KNN</tag>
         
        <tag>贝叶斯分类器</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/06/24/edx-columbia-5-Bayes-Linear-Regression/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>EdX Columbia ML 5. 贝叶斯线性回归</title>
        <pubTime>2017-06-24T15:45:50.000Z</pubTime>
        
        <tag>线性回归</tag>
         
        <tag>EdX-Columbia</tag>
         
        <tag>贝叶斯</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
  <url>
    <loc>txshi-mt.com/2017/06/28/edx-columbia-9-Logistic-Regression-Laplace-Approximation/</loc>
    <lastmod>2017-12-19T12:35:39.000Z</lastmod>
    <data>
        <display>
        <title>EdX Columbia ML 9. Logistic回归与拉普拉斯近似</title>
        <pubTime>2017-06-28T07:45:23.000Z</pubTime>
        
        <tag>Logistic回归</tag>
         
        <tag>EdX-Columbia</tag>
         
        <tag>拉普拉斯近似</tag>
         
         
           
             
              <breadCrumb title="统计机器学习" url="txshi-mt.com/categories/%E7%BB%9F%E8%AE%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
          
        </display>
    </data>
    </url>

    
    
    
</urlset>